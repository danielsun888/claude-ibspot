# Reddit äº§å“å…³é”®è¯çˆ¬è™«

ä¸€ä¸ªç”¨äºçˆ¬å– Reddit ä¸Šäº§å“ç›¸å…³è®¨è®ºå’Œå…³é”®è¯çš„ Python å·¥å…·ã€‚

## åŠŸèƒ½ç‰¹ç‚¹

- ğŸ” æŒ‰å…³é”®è¯æœç´¢å¤šä¸ª subreddit
- ğŸ“Š è·å–å¸–å­è¯¦ç»†ä¿¡æ¯ï¼ˆæ ‡é¢˜ã€å†…å®¹ã€è¯„åˆ†ã€è¯„è®ºæ•°ç­‰ï¼‰
- ğŸ’¾ æ”¯æŒå¯¼å‡ºä¸º JSON å’Œ CSV æ ¼å¼
- âš™ï¸ çµæ´»çš„é…ç½®ç³»ç»Ÿ
- ğŸ”’ ä½¿ç”¨å®˜æ–¹ Reddit APIï¼Œå®‰å…¨ç¨³å®š

## é¡¹ç›®ç»“æ„

```
reddit-scraper/
â”œâ”€â”€ scraper.py          # ä¸»çˆ¬è™«è„šæœ¬
â”œâ”€â”€ config.json         # é…ç½®æ–‡ä»¶ï¼ˆå…³é”®è¯ã€å­ç‰ˆå—ç­‰ï¼‰
â”œâ”€â”€ requirements.txt    # Python ä¾èµ–
â”œâ”€â”€ .env.example        # ç¯å¢ƒå˜é‡ç¤ºä¾‹
â”œâ”€â”€ .env                # ç¯å¢ƒå˜é‡ï¼ˆéœ€è‡ªè¡Œåˆ›å»ºï¼‰
â”œâ”€â”€ README.md           # æœ¬æ–‡ä»¶
â””â”€â”€ data/               # æ•°æ®è¾“å‡ºç›®å½•
    â”œâ”€â”€ reddit_results_*.json
    â””â”€â”€ reddit_results_*.csv
```

## å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–

```bash
cd reddit-scraper
pip install -r requirements.txt
```

### 2. è·å– Reddit API å‡­è¯

1. è®¿é—® [Reddit Apps](https://www.reddit.com/prefs/apps)
2. ç‚¹å‡» "Create App" æˆ– "Create Another App"
3. å¡«å†™ä¿¡æ¯ï¼š
   - **name**: åº”ç”¨åç§°ï¼ˆä¾‹å¦‚ï¼šProduct Keyword Scraperï¼‰
   - **App type**: é€‰æ‹© "script"
   - **description**: åº”ç”¨æè¿°ï¼ˆå¯é€‰ï¼‰
   - **about url**: ç•™ç©º
   - **redirect uri**: å¡«å†™ `http://localhost:8080`
4. ç‚¹å‡» "Create app"
5. è®°ä¸‹ä»¥ä¸‹ä¿¡æ¯ï¼š
   - **Client ID**: åœ¨åº”ç”¨åç§°ä¸‹æ–¹çš„ä¸€ä¸²å­—ç¬¦
   - **Client Secret**: "secret" å­—æ®µçš„å€¼

### 3. é…ç½®ç¯å¢ƒå˜é‡

å¤åˆ¶ `.env.example` ä¸º `.env`ï¼š

```bash
cp .env.example .env
```

ç¼–è¾‘ `.env` æ–‡ä»¶ï¼Œå¡«å…¥ä½ çš„ Reddit API å‡­è¯ï¼š

```env
REDDIT_CLIENT_ID=ä½ çš„_client_id
REDDIT_CLIENT_SECRET=ä½ çš„_client_secret
REDDIT_USER_AGENT=python:reddit-keyword-scraper:v1.0 (by /u/ä½ çš„Redditç”¨æˆ·å)
```

### 4. é…ç½®æœç´¢å‚æ•°

ç¼–è¾‘ `config.json` è‡ªå®šä¹‰æœç´¢å…³é”®è¯å’Œå­ç‰ˆå—ï¼š

```json
{
  "keywords": [
    "kbeauty",
    "korean beauty",
    "skincare"
  ],
  "subreddits": [
    "kbeauty",
    "AsianBeauty",
    "SkincareAddiction"
  ],
  "limit": 50
}
```

### 5. è¿è¡Œçˆ¬è™«

```bash
python scraper.py
```

## é…ç½®è¯´æ˜

### config.json å‚æ•°

| å‚æ•° | è¯´æ˜ | ç¤ºä¾‹ |
|------|------|------|
| `keywords` | è¦æœç´¢çš„å…³é”®è¯åˆ—è¡¨ | `["kbeauty", "skincare"]` |
| `subreddits` | è¦æœç´¢çš„å­ç‰ˆå—åˆ—è¡¨ | `["kbeauty", "AsianBeauty"]` |
| `limit` | æ¯æ¬¡æœç´¢è¿”å›çš„æœ€å¤§ç»“æœæ•° | `50` |
| `time_filter` | æ—¶é—´è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰ | `"week"` / `"month"` / `"year"` |

### æ¨èçš„ç¾å¦†ç›¸å…³ Subreddits

- `kbeauty` - éŸ©å›½ç¾å¦†
- `AsianBeauty` - äºšæ´²ç¾å¦†
- `SkincareAddiction` - æŠ¤è‚¤è®¨è®º
- `beauty` - ä¸€èˆ¬ç¾å¦†
- `MakeupAddiction` - å½©å¦†
- `koreanbeauty` - éŸ©å›½ç¾å¦†äº§å“

## è¾“å‡ºæ•°æ®æ ¼å¼

### JSON æ ¼å¼ç¤ºä¾‹

```json
[
  {
    "id": "abc123",
    "title": "Best Korean Sunscreen 2024",
    "author": "username",
    "created_utc": "2024-01-15T10:30:00",
    "score": 245,
    "upvote_ratio": 0.95,
    "num_comments": 42,
    "url": "https://reddit.com/...",
    "permalink": "https://reddit.com/r/kbeauty/...",
    "selftext": "å¸–å­å†…å®¹...",
    "subreddit": "kbeauty",
    "keyword": "korean beauty"
  }
]
```

### CSV æ ¼å¼

åŒ…å«ç›¸åŒçš„å­—æ®µï¼Œä¾¿äºåœ¨ Excel æˆ– Google Sheets ä¸­åˆ†æã€‚

## ä½¿ç”¨åœºæ™¯

- ğŸ“ˆ äº§å“å¸‚åœºè°ƒç ”
- ğŸ’¬ ç”¨æˆ·åé¦ˆæ”¶é›†
- ğŸ”¥ çƒ­é—¨è¯é¢˜è¿½è¸ª
- ğŸ¯ ç«å“åˆ†æ
- ğŸ“ å†…å®¹åˆ›ä½œçµæ„Ÿ

## æ³¨æ„äº‹é¡¹

1. **API é™åˆ¶**: Reddit API æœ‰é€Ÿç‡é™åˆ¶ï¼Œå»ºè®®ä¸è¦é¢‘ç¹è¿è¡Œ
2. **åˆè§„ä½¿ç”¨**: éµå®ˆ Reddit API ä½¿ç”¨æ¡æ¬¾å’Œç¤¾åŒºè§„åˆ™
3. **æ•°æ®éšç§**: ä¸è¦çˆ¬å–å’Œå­˜å‚¨ä¸ªäººéšç§ä¿¡æ¯
4. **å¤‡ä»½ .env**: ä¸è¦å°† `.env` æ–‡ä»¶æäº¤åˆ° git ä»“åº“

## å¸¸è§é—®é¢˜

### Q: æ˜¾ç¤º "401 Unauthorized" é”™è¯¯ï¼Ÿ
A: æ£€æŸ¥ `.env` æ–‡ä»¶ä¸­çš„ API å‡­è¯æ˜¯å¦æ­£ç¡®ã€‚

### Q: æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç»“æœï¼Ÿ
A: æ£€æŸ¥å…³é”®è¯æ˜¯å¦æ­£ç¡®ï¼Œæˆ–å°è¯•æ›´é€šç”¨çš„å…³é”®è¯ã€‚

### Q: å¦‚ä½•æœç´¢æ›´å¤šç»“æœï¼Ÿ
A: åœ¨ `config.json` ä¸­å¢åŠ  `limit` å‚æ•°çš„å€¼ã€‚

### Q: å¯ä»¥æœç´¢ä¸­æ–‡å…³é”®è¯å—ï¼Ÿ
A: å¯ä»¥ï¼Œä½† Reddit ä¸Šè‹±æ–‡å†…å®¹è¾ƒå¤šï¼Œä¸­æ–‡å…³é”®è¯å¯èƒ½ç»“æœè¾ƒå°‘ã€‚

## é«˜çº§ç”¨æ³•

### è‡ªå®šä¹‰æœç´¢

ç›´æ¥åœ¨ Python ä¸­ä½¿ç”¨ RedditScraper ç±»ï¼š

```python
from scraper import RedditScraper

scraper = RedditScraper()

# æœç´¢ç‰¹å®šå…³é”®è¯
results = scraper.search_keywords('kbeauty', 'SkincareAddiction', limit=100)

# è·å–çƒ­é—¨å¸–å­
top_posts = scraper.get_top_posts('kbeauty', time_filter='month', limit=50)

# ä¿å­˜ç»“æœ
scraper.save_results(results, format='json')
```

## æŠ€æœ¯æ ˆ

- Python 3.7+
- PRAW (Python Reddit API Wrapper)
- python-dotenv
- pandas (å¯é€‰)

## è®¸å¯è¯

MIT License

## è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## ç›¸å…³èµ„æº

- [PRAW æ–‡æ¡£](https://praw.readthedocs.io/)
- [Reddit API æ–‡æ¡£](https://www.reddit.com/dev/api/)
- [Reddit API ä½¿ç”¨æ¡æ¬¾](https://www.redditinc.com/policies/data-api-terms)
